{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qusetion 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a). Please fill in the missing code to train 3 different MLPs. And then compare their accuracy values by plotting a bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-324-fd8ed88fe452>:58: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = m(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.304981\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.301955\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 2.296881\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 2.297209\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 2.290030\n",
      "\n",
      "Validation set: Average loss: 2.2941, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 2.293878\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 2.302991\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 2.292756\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 2.270677\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 2.300769\n",
      "\n",
      "Validation set: Average loss: 2.2703, Accuracy: 2044/10000 (20.44%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 2.279945\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 2.247510\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 2.246030\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 2.215213\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 2.214111\n",
      "\n",
      "Validation set: Average loss: 2.2146, Accuracy: 2252/10000 (22.52%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 2.170541\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 2.224120\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 2.179765\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 2.207393\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 2.146856\n",
      "\n",
      "Validation set: Average loss: 2.1687, Accuracy: 2983/10000 (29.83%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 2.202185\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 2.194038\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 2.094715\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 2.110073\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 2.113721\n",
      "\n",
      "Validation set: Average loss: 2.1324, Accuracy: 3028/10000 (30.28%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.303108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-324-fd8ed88fe452>:83: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.294462\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 2.281948\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 2.233108\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 2.232159\n",
      "\n",
      "Validation set: Average loss: 2.1605, Accuracy: 5249/10000 (52.49%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 2.152149\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 2.036529\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 1.983967\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 1.896583\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 1.895409\n",
      "\n",
      "Validation set: Average loss: 1.8067, Accuracy: 7839/10000 (78.39%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 1.705642\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 1.750786\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 1.718154\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 1.730124\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 1.783513\n",
      "\n",
      "Validation set: Average loss: 1.7007, Accuracy: 8178/10000 (81.78%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 1.704236\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 1.688158\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 1.685067\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 1.816040\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 1.707051\n",
      "\n",
      "Validation set: Average loss: 1.6690, Accuracy: 8298/10000 (82.98%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 1.669155\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 1.672455\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 1.652728\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 1.618586\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 1.658158\n",
      "\n",
      "Validation set: Average loss: 1.6539, Accuracy: 8351/10000 (83.51%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.301417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-324-fd8ed88fe452>:107: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.297590\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 2.286959\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 2.260871\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 2.235079\n",
      "\n",
      "Validation set: Average loss: 2.1904, Accuracy: 4796/10000 (47.96%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 2.235173\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 2.082625\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 1.998516\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 1.991316\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 1.939898\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-324-fd8ed88fe452>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m     \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlossv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-324-fd8ed88fe452>\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(loss_vector, accuracy_vector)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalidation_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \"\"\"\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m255\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteStorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbands\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mtobytes\u001b[0;34m(self, encoder_name, *args)\u001b[0m\n\u001b[1;32m    734\u001b[0m         \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetimage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m         \u001b[0mbufsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m65536\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# see RawEncode.c\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device('cpu')\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_transform = transforms.Compose([ transforms.ToTensor()])\n",
    "\n",
    "test_transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_dataset = datasets.MNIST('./data', \n",
    "                               train=True, \n",
    "                               download=True, \n",
    "                               transform=train_transform)\n",
    "\n",
    "validation_dataset = datasets.MNIST('./data', \n",
    "                                    train=False, \n",
    "                                    transform=test_transform)\n",
    "\n",
    "## construct the loader for training\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "\n",
    "## construct the loader for validation\n",
    "validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=batch_size,\n",
    "                                         shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "class Net1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net1, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(28*28, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        \n",
    "        ## forward x to the first fully connected layer.\n",
    "        x = self.fc1(x)\n",
    "        \n",
    "        ## forward x to sigmoid activation function.\n",
    "        x = torch.sigmoid(x)\n",
    "        \n",
    "        ## forward x to the second fully connected layer.\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        ## forward x to softmax activation function.\n",
    "        m = nn.Softmax()\n",
    "        x = m(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    \n",
    "class Net2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net2, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(28*28, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        \n",
    "        ## forward x to the first fully connected layer.\n",
    "        x = self.fc1(x)\n",
    "        \n",
    "        ## forward x to relu activation function.\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        ## forward x to the second fully connected layer.\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        ## forward x to softmax activation function.\n",
    "        x = F.softmax(x)\n",
    "        \n",
    "        return x    \n",
    "\n",
    "class Net3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net3, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(28*28, 16)\n",
    "        self.fc2 = nn.Linear(16, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        \n",
    "        ## forward x to the first fully connected layer.\n",
    "        x = self.fc1(x)\n",
    "        \n",
    "        ## forward x to relu activation function.\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        ## forward x to the second fully connected layer.\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        ## forward x to softmax activation function.\n",
    "        x = F.softmax(x)\n",
    "        \n",
    "        return x   \n",
    "    \n",
    "def train(epoch, log_interval=200):\n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        ## zero gradient buffers\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        ## pass data through the network\n",
    "        output = model(data)\n",
    "\n",
    "        ## calculate loss\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        ## backpropagate\n",
    "        loss.backward()\n",
    "        \n",
    "        ## update weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data.item()))\n",
    "\n",
    "def validate(loss_vector, accuracy_vector):\n",
    "    model.eval()\n",
    "    val_loss, correct = 0, 0\n",
    "    for data, target in validation_loader:\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        output = model(data)\n",
    "        val_loss += criterion(output, target).data.item()\n",
    "        \n",
    "        pred = output.data.max(1)[1]\n",
    "        \n",
    "        correct += pred.eq(target.data).sum()\n",
    "\n",
    "    val_loss /= len(validation_loader)\n",
    "    loss_vector.append(val_loss)\n",
    "\n",
    "    accuracy = 100. * correct.to(torch.float32) / len(validation_loader.dataset)\n",
    "    accuracy_vector.append(accuracy)\n",
    "    \n",
    "    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        val_loss, correct, len(validation_loader.dataset), accuracy))\n",
    "\n",
    "## Trainig and evaluating 1) MLP\n",
    "model = Net1().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "\n",
    "## define the crosstntropy loss.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 5\n",
    "lossv, accv = [], []\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)\n",
    "    validate(lossv, accv)\n",
    "\n",
    "    \n",
    "## Trainig and evaluating 2) MLP\n",
    "model = Net2().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "\n",
    "## define the crosstntropy loss.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 5\n",
    "lossv, accv = [], []\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)\n",
    "    validate(lossv, accv)\n",
    "\n",
    "## Trainig and evaluating 3) MLP\n",
    "model = Net3().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "\n",
    "## define the crosstntropy loss.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 5\n",
    "lossv, accv = [], []\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)\n",
    "    validate(lossv, accv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b). Please change the batch size and learning rate to train (2) MLP (Net2）as above. And then compare their accuracy values by plotting a matrix with values and colormap. Please note that each time you change the setting and train the MLP, you need to initialize the model again (e.g. \"model = Net2().to(device)\"). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.302820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-56-5671d7163faf>:85: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.298860\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 2.294057\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 2.289768\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 2.287861\n",
      "\n",
      "Validation set: Average loss: 2.2736, Accuracy: 3793/10000 (37.93%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 2.273050\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 2.242797\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 2.217850\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 2.216009\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 2.204115\n",
      "\n",
      "Validation set: Average loss: 2.1667, Accuracy: 4577/10000 (45.77%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 2.169247\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 2.124745\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 2.095454\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 2.070521\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 2.070521\n",
      "\n",
      "Validation set: Average loss: 1.9693, Accuracy: 5698/10000 (56.98%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 1.951683\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 2.006759\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 1.939594\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 1.850737\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 1.918111\n",
      "\n",
      "Validation set: Average loss: 1.8630, Accuracy: 6534/10000 (65.34%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 1.828798\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 1.846523\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 1.890117\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 1.838388\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 1.763685\n",
      "\n",
      "Validation set: Average loss: 1.7877, Accuracy: 7485/10000 (74.85%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.303617\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.299872\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 2.296390\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 2.293040\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 2.283610\n",
      "\n",
      "Validation set: Average loss: 2.2793, Accuracy: 2372/10000 (23.72%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 2.282267\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 2.271748\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 2.254549\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 2.237643\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 2.225111\n",
      "\n",
      "Validation set: Average loss: 2.1832, Accuracy: 4045/10000 (40.45%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 2.183414\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 2.157911\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 2.094267\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 2.058356\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 2.049664\n",
      "\n",
      "Validation set: Average loss: 1.9749, Accuracy: 6580/10000 (65.80%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 1.984536\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 1.937387\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 1.840927\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 1.893155\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 1.846952\n",
      "\n",
      "Validation set: Average loss: 1.8450, Accuracy: 7064/10000 (70.64%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 1.826503\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 1.818667\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 1.742042\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 1.814384\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 1.785963\n",
      "\n",
      "Validation set: Average loss: 1.7904, Accuracy: 7283/10000 (72.83%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.301791\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.292000\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 2.274746\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 2.249038\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 2.168185\n",
      "\n",
      "Validation set: Average loss: 2.1511, Accuracy: 5488/10000 (54.88%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 2.154629\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 2.053919\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 1.994682\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 1.904500\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 1.819120\n",
      "\n",
      "Validation set: Average loss: 1.8034, Accuracy: 7512/10000 (75.12%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 1.815418\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 1.718671\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 1.747630\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 1.699548\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 1.719677\n",
      "\n",
      "Validation set: Average loss: 1.7010, Accuracy: 8184/10000 (81.84%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 1.726639\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 1.731560\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 1.634882\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 1.761927\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 1.620108\n",
      "\n",
      "Validation set: Average loss: 1.6695, Accuracy: 8297/10000 (82.97%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 1.707750\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 1.637005\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 1.720812\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 1.701872\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 1.701003\n",
      "\n",
      "Validation set: Average loss: 1.6543, Accuracy: 8363/10000 (83.63%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.301852\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.294050\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 2.261974\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 2.214338\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 2.194877\n",
      "\n",
      "Validation set: Average loss: 2.1571, Accuracy: 4425/10000 (44.25%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 2.154465\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 2.090786\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 1.951998\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 1.925371\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 1.826734\n",
      "\n",
      "Validation set: Average loss: 1.8187, Accuracy: 7256/10000 (72.56%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 1.816121\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 1.732927\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 1.769893\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 1.753014\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 1.762951\n",
      "\n",
      "Validation set: Average loss: 1.7517, Accuracy: 7450/10000 (74.50%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 1.673512\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 1.723700\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 1.753399\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 1.746832\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 1.687677\n",
      "\n",
      "Validation set: Average loss: 1.6906, Accuracy: 8265/10000 (82.65%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 1.699621\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 1.736054\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 1.677123\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 1.685284\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 1.678671\n",
      "\n",
      "Validation set: Average loss: 1.6628, Accuracy: 8348/10000 (83.48%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.301227\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.288255\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 2.173194\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 2.085895\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 1.937958\n",
      "\n",
      "Validation set: Average loss: 1.8640, Accuracy: 6506/10000 (65.06%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 1.861100\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 1.798002\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 1.852121\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 1.766962\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 1.688081\n",
      "\n",
      "Validation set: Average loss: 1.6876, Accuracy: 8194/10000 (81.94%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 1.699127\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 1.752125\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 1.635961\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 1.698618\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 1.659417\n",
      "\n",
      "Validation set: Average loss: 1.6509, Accuracy: 8349/10000 (83.49%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 1.725077\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 1.641043\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 1.636089\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 1.635193\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 1.601701\n",
      "\n",
      "Validation set: Average loss: 1.6370, Accuracy: 8420/10000 (84.20%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 1.774568\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 1.614883\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 1.606210\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 1.642189\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 1.623376\n",
      "\n",
      "Validation set: Average loss: 1.5911, Accuracy: 8976/10000 (89.76%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.303714\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.292115\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 2.216955\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 2.010828\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 1.891135\n",
      "\n",
      "Validation set: Average loss: 1.8139, Accuracy: 7268/10000 (72.68%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 1.801185\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 1.717159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 1.729365\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 1.681624\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 1.700889\n",
      "\n",
      "Validation set: Average loss: 1.6720, Accuracy: 8279/10000 (82.79%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 1.665691\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 1.722733\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 1.704407\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 1.649947\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 1.627935\n",
      "\n",
      "Validation set: Average loss: 1.6464, Accuracy: 8379/10000 (83.79%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 1.652061\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 1.661813\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 1.698032\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 1.668378\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 1.702370\n",
      "\n",
      "Validation set: Average loss: 1.6353, Accuracy: 8416/10000 (84.16%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 1.617200\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 1.754087\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 1.627303\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 1.669095\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 1.674876\n",
      "\n",
      "Validation set: Average loss: 1.6286, Accuracy: 8451/10000 (84.51%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Trainig and evaluating 2) MLP with the first setting\n",
    "batch_size = 64\n",
    "model = Net2().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.005, momentum=0.5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "epochs = 5\n",
    "lossv, accv = [], []\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)\n",
    "    validate(lossv, accv)\n",
    "accuracy_matrix[0, 0] = accv[-1]\n",
    "\n",
    "## Trainig and evaluating 2) MLP with the second setting\n",
    "batch_size = 128\n",
    "model = Net2().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.005, momentum=0.5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "epochs = 5\n",
    "lossv, accv = [], []\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)\n",
    "    validate(lossv, accv)\n",
    "accuracy_matrix[1, 0] = accv[-1]\n",
    "    \n",
    "## Trainig and evaluating 2) MLP with the third setting\n",
    "batch_size = 64\n",
    "model = Net2().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "epochs = 5\n",
    "lossv, accv = [], []\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)\n",
    "    validate(lossv, accv)\n",
    "accuracy_matrix[0, 1] = accv[-1]\n",
    "\n",
    "## Trainig and evaluating 2) MLP with the fourth setting\n",
    "batch_size = 128\n",
    "model = Net2().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "epochs = 5\n",
    "lossv, accv = [], []\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)\n",
    "    validate(lossv, accv)\n",
    "accuracy_matrix[1, 1] = accv[-1]\n",
    "\n",
    "\n",
    "## Trainig and evaluating 2) MLP with the fifth setting\n",
    "batch_size = 64\n",
    "model = Net2().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.02, momentum=0.5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "epochs = 5\n",
    "lossv, accv = [], []\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)\n",
    "    validate(lossv, accv)\n",
    "accuracy_matrix[0, 2] = accv[-1]\n",
    "\n",
    "\n",
    "## Trainig and evaluating 2) MLP with the sixth setting\n",
    "batch_size = 128\n",
    "model = Net2().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.02, momentum=0.5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "epochs = 5\n",
    "lossv, accv = [], []\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)\n",
    "    validate(lossv, accv)\n",
    "accuracy_matrix[1, 2] = accv[-1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_set = [64,128]\n",
    "learning_rate_set = [0.005, 0.01, 0.02]\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(accuracy_matrix, cmap=plt.cm.Blues)\n",
    "for i in range(2):\n",
    "    for j in range(3):\n",
    "        c = round( accuracy_matrix[i,j], 2)\n",
    "        ax.text(j,i , str(c), va='center', ha='center')\n",
    "        \n",
    "ax.set_xticks(np.arange(len(learning_rate_set)))\n",
    "ax.set_yticks(np.arange(len(batch_set)))\n",
    "ax.set_xticklabels(learning_rate_set)\n",
    "ax.set_yticklabels(batch_set)\n",
    "ax.set_xlabel(\"learning rate\")\n",
    "ax.set_ylabel(\"batch size\")\n",
    "ax.set_title(\"Accuracy values\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please use “dropout”, “batch normalization” and any “data augmentation” to train to improve the accuracy of (2) MLP (Net2）in Question 1 a. (Batch size is 64 and learning rate is 0.01). Please describe clearly your design choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training images -  60000\n",
      "Size of images -  torch.Size([28, 28])\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device('cpu')\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize(0.5,0.5)])\n",
    "\n",
    "test_transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize(0.5,0.5)])\n",
    "\n",
    "\n",
    "print(\"Number of training images - \", len(train_dataset.data))\n",
    "print(\"Size of images - \", train_dataset.data[0].shape)\n",
    "\n",
    "\n",
    "train_dataset = datasets.MNIST('./data', \n",
    "                               train=True, \n",
    "                               download=True, \n",
    "                               transform=train_transform)\n",
    "\n",
    "\n",
    "# print( train_dataset.__getitem__(1) )\n",
    "validation_dataset = datasets.MNIST('./data', \n",
    "                                    train=False, \n",
    "                                    transform=test_transform)\n",
    "\n",
    "## construct the loader for training\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "\n",
    "## construct the loader for validation\n",
    "validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=batch_size,\n",
    "                                         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n",
      "torch.Size([64, 1, 56, 56])\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        m = nn.Dropout(p=0.25)\n",
    "        data = m(data)\n",
    "\n",
    "        \n",
    "        m = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "        data = m(data)\n",
    "        \n",
    "        print(data.shape)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# class Net2(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Net2, self).__init__()\n",
    "        \n",
    "#         self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3)\n",
    "#         self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "#         self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n",
    "#         x = torch.randn(28,28).view(-1,1,28,28)\n",
    "#         self._to_linear = None\n",
    "#         self.convs(x)\n",
    "#         self.fc1 = nn.Linear(self._to_linear, 128)\n",
    "#         self.fc2 = nn.Linear(128, 10)\n",
    "#     def convs(self, x):\n",
    "#         # Conv - DropOut - BatchNorm - Activation - Pool \n",
    "        \n",
    "#         # 1st Conv \n",
    "#         x = self.conv1(x)\n",
    "        \n",
    "#         # dropout\n",
    "#         m = nn.Dropout(p=0.25)\n",
    "#         x = m(x)\n",
    "        \n",
    "#         #batch norm\n",
    "#         m2 = nn.BatchNorm2d(32, affine=False)\n",
    "#         x = m2(x)\n",
    "        \n",
    "#         #activation\n",
    "#         x = F.relu(x)\n",
    "        \n",
    "#         #2nd conv\n",
    "#         x = self.conv2(x)\n",
    "        \n",
    "#         #activation\n",
    "#         x = F.relu(x)\n",
    "        \n",
    "#         # batch norm\n",
    "#         m2 = nn.BatchNorm2d(64, affine=False)\n",
    "#         x = m2(x)\n",
    "        \n",
    "#         #pooling\n",
    "#         x = self.pool(x)\n",
    "        \n",
    "#         #dropout\n",
    "#         m = nn.Dropout(p=0.25)\n",
    "#         x = m(x)\n",
    "        \n",
    "#         if self._to_linear is None:\n",
    "#             self._to_linear = x[0].shape[0]*x[0].shape[1]*x[0].shape[2]\n",
    "#         return x\n",
    "\n",
    "#     def forward(self, x):\n",
    "\n",
    "#         x = self.convs(x)\n",
    "\n",
    "#         x = x.view(-1, self._to_linear )\n",
    "        \n",
    "#         ## forward x to the first fully connected layer.\n",
    "#         x = self.fc1(x)\n",
    "        \n",
    "#         ## forward x to relu activation function.\n",
    "#         x = F.relu(x)\n",
    "        \n",
    "#         ## forward x to the second fully connected layer.\n",
    "#         x = self.fc2(x)\n",
    "        \n",
    "#         ## forward x to softmax activation function.\n",
    "#         x = F.softmax(x, dim=1)\n",
    "        \n",
    "#         return x    \n",
    "\n",
    "# net = Net2()\n",
    "# print(net)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net2(\n",
      "  (fc1): Linear(in_features=38416, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net2, self).__init__()\n",
    "               \n",
    "        self.fc1 = nn.Linear(28*28*49, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "   \n",
    "      \n",
    "    def forward(self, x):\n",
    "   \n",
    "        \n",
    "        m = nn.UpsamplingNearest2d(scale_factor=7)\n",
    "        x = m(x)\n",
    "        \n",
    "        \n",
    "        # dropout\n",
    "        m = nn.Dropout(p=0.25)\n",
    "        x = m(x)\n",
    "        \n",
    "       \n",
    "        #batch norm\n",
    "        m2 = nn.BatchNorm2d(1, affine=False)\n",
    "        x = m2(x)\n",
    "        \n",
    "        \n",
    "        x = x.view(-1, x[0].shape[0]*x[0].shape[1]*x[0].shape[2] )\n",
    "        \n",
    "        ## forward x to the first fully connected layer.\n",
    "        x = self.fc1(x)\n",
    "        \n",
    "        \n",
    "        ## forward x to relu activation function.\n",
    "        x = F.relu(x)\n",
    "\n",
    "\n",
    "        ## forward x to the second fully connected layer.\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        ## forward x to softmax activation function.\n",
    "        x = F.softmax(x, dim=1)\n",
    "        \n",
    "        return x    \n",
    "\n",
    "net = Net2()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.302084\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 1.539234\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 1.528965\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 1.577664\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 1.553203\n",
      "\n",
      "Validation set: Average loss: 1.5273, Accuracy: 9403/10000 (94.03%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 1.538511\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 1.549514\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 1.553532\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 1.525028\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 1.498407\n",
      "\n",
      "Validation set: Average loss: 1.5087, Accuracy: 9566/10000 (95.66%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 1.528729\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 1.479157\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 1.520704\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 1.528379\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 1.492247\n",
      "\n",
      "Validation set: Average loss: 1.5020, Accuracy: 9620/10000 (96.20%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 1.525223\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 1.489544\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 1.471701\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 1.499173\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 1.522558\n",
      "\n",
      "Validation set: Average loss: 1.4984, Accuracy: 9658/10000 (96.58%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 1.491054\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 1.484145\n"
     ]
    }
   ],
   "source": [
    "def train(epoch, log_interval=200):\n",
    "    model.train()\n",
    "    \n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        ## zero gradient buffers\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        ## pass data through the network\n",
    "        output = model(data)\n",
    "        \n",
    "        \n",
    "        pred = output.data.max(1)[1]\n",
    "\n",
    "        ## calculate loss\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        ## backpropagate\n",
    "        loss.backward()\n",
    "        \n",
    "        ## update weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data.item()))\n",
    "        \n",
    "        \n",
    "        \n",
    "def validate(loss_vector, accuracy_vector):\n",
    "    model.eval()\n",
    "    val_loss, correct = 0, 0\n",
    "    \n",
    "    pred_all = []\n",
    "    for data, target in validation_loader:\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        output = model(data)\n",
    "        val_loss += criterion(output, target).data.item()\n",
    "        \n",
    "        pred = output.data.max(1)[1]\n",
    "        \n",
    "        pred_all.extend(pred)\n",
    "        \n",
    "        correct += pred.eq(target.data).sum()\n",
    "\n",
    "    val_loss /= len(validation_loader)\n",
    "    loss_vector.append(val_loss)\n",
    "\n",
    "    accuracy = 100. * correct.to(torch.float32) / len(validation_loader.dataset)\n",
    "    accuracy_vector.append(accuracy)\n",
    "    \n",
    "    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        val_loss, correct, len(validation_loader.dataset), accuracy))\n",
    "    \n",
    "    \n",
    "    pred_all = np.array(pred_all)\n",
    "\n",
    "    return pred_all\n",
    "\n",
    "    \n",
    "## Trainig and evaluating 2) MLP\n",
    "model = Net2().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.02, momentum=0.5)\n",
    "\n",
    "## define the crosstntropy loss.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 20\n",
    "lossv, accv = [], []\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)\n",
    "    pred_all = validate(lossv,accv)\n",
    "\n",
    "np.save('results.npy',pred_all)\n",
    "\n",
    "\n",
    "print(np.shape(pred_all))\n",
    "#     validate(lossv, accv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please complete the missing code to use RBM to initialize the parameters of the (1) MLP (Net1) in Question 1 a. Compare the accuracy values with and without RBM pretraining by plotting a bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RBM...\n",
      "Epoch Error (epoch=0): 0.2416\n",
      "Epoch Error (epoch=1): 0.2415\n",
      "Epoch Error (epoch=2): 0.2414\n",
      "Epoch Error (epoch=3): 0.2415\n",
      "Epoch Error (epoch=4): 0.2413\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device('cpu')\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_transform = transforms.Compose([ transforms.ToTensor(),\n",
    "                                    ])\n",
    "\n",
    "test_transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                    ])\n",
    "\n",
    "train_dataset = datasets.MNIST('./data', \n",
    "                               train=True, \n",
    "                               download=True, \n",
    "                               transform=train_transform)\n",
    "\n",
    "validation_dataset = datasets.MNIST('./data', \n",
    "                                    train=False, \n",
    "                                    transform=test_transform)\n",
    "\n",
    "## construct the loader for training\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "\n",
    "## construct the loader for validation\n",
    "validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=batch_size,\n",
    "                                         shuffle=False)\n",
    "\n",
    "class RBM():\n",
    "\n",
    "    def __init__(self, num_visible, num_hidden, k, learning_rate=0.1):\n",
    "        self.num_visible = num_visible\n",
    "        self.num_hidden = num_hidden\n",
    "        self.k = k\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        self.weights = torch.randn(num_visible, num_hidden) * 0.01\n",
    "        self.visible_bias = torch.ones(num_visible) * 0.01\n",
    "        self.hidden_bias = torch.zeros(num_hidden)\n",
    "        \n",
    "    def _sigmoid(self, x):\n",
    "        return 1 / (1 + torch.exp(-x))\n",
    "\n",
    "    def _random_probabilities(self, num):\n",
    "        random_probabilities = torch.rand(num)\n",
    "        return random_probabilities\n",
    "    \n",
    "## compute the probability of hidden nodes given visible nodes.\n",
    "    def compute_hidden(self, visible_probabilities):\n",
    "        \n",
    "        hidden_activations = torch.matmul(visible_probabilities, self.weights) + self.hidden_bias\n",
    "        \n",
    "        hidden_probabilities = self._sigmoid(hidden_activations)\n",
    "        return hidden_probabilities\n",
    "\n",
    "## compute the probability of visible nodes given hidden nodes.\n",
    "    def compute_visible(self, hidden_probabilities):\n",
    "        \n",
    "        visible_activations = torch.matmul(hidden_probabilities, self.weights.t()) + self.visible_bias\n",
    "        \n",
    "        visible_probabilities = self._sigmoid(visible_activations)\n",
    "        return visible_probabilities\n",
    "    \n",
    "## Contrastive Divergence (CD-k)\n",
    "    def contrastive_divergence(self, input_data):\n",
    "        \n",
    "        positive_hidden_probabilities = self.compute_hidden(input_data)\n",
    "        \n",
    "        ## sample a hidden activation vector from its probability distribution\n",
    "        positive_hidden_activations = (positive_hidden_probabilities >= self._random_probabilities(self.num_hidden)).float()\n",
    "        \n",
    "        \n",
    "        ## compute the positive gradient\n",
    "        positive_associations = torch.matmul(input_data.t(), positive_hidden_activations)\n",
    "\n",
    "\n",
    "        hidden_activations = positive_hidden_activations\n",
    "\n",
    "        for step in range(self.k):\n",
    "            visible_probabilities = self.compute_visible(hidden_activations)\n",
    "            hidden_probabilities = self.compute_hidden(visible_probabilities)\n",
    "            \n",
    "            ## resample a hidden activation vector from its probability distribution\n",
    "            hidden_activations = (hidden_probabilities >= self._random_probabilities(self.num_hidden)).float()\n",
    "\n",
    "\n",
    "        negative_visible_probabilities = visible_probabilities\n",
    "        negative_hidden_probabilities = hidden_probabilities\n",
    "        \n",
    "        ## compute the nagetive gradient\n",
    "        negative_associations = torch.matmul(negative_visible_probabilities.t(), negative_hidden_probabilities)\n",
    "\n",
    "        \n",
    "        batch_size = input_data.size(0)\n",
    "        \n",
    "        ## update weights\n",
    "        self.weights = (positive_associations - negative_associations) * self.learning_rate / batch_size\n",
    "        \n",
    "        ## update bias of visible units\n",
    "        self.visible_bias = torch.sum(input_data - negative_visible_probabilities, dim=0) * self.learning_rate / batch_size\n",
    "\n",
    "        ## update bias of hidden units\n",
    "        self.hidden_bias = torch.sum(positive_hidden_probabilities - negative_hidden_probabilities, dim=0) * self.learning_rate / batch_size\n",
    "\n",
    "        ## compute reconstruction error\n",
    "        error = torch.mean((input_data - negative_visible_probabilities)**2)\n",
    "\n",
    "        return error\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "VISIBLE_UNITS = 784  # 28 x 28 images\n",
    "HIDDEN_UNITS = 128\n",
    "CD_K = 3\n",
    "EPOCHS = 5\n",
    "\n",
    "########## TRAINING RBM ##########\n",
    "print('Training RBM...')\n",
    "\n",
    "rbm = RBM(VISIBLE_UNITS, HIDDEN_UNITS, CD_K)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    epoch_error = 0.0\n",
    "    num_batch = 0\n",
    "    for batch, _ in train_loader:\n",
    "        batch = batch.view(len(batch), VISIBLE_UNITS)  # flatten input data\n",
    "\n",
    "        batch_error = rbm.contrastive_divergence(batch)\n",
    "        epoch_error += batch_error\n",
    "        num_batch = num_batch + 1\n",
    "\n",
    "    print('Epoch Error (epoch=%d): %.4f' % (epoch, epoch_error/num_batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now check whether the trained RBM model can extract features from the images.\n",
    "\n",
    "We calculate the probability of hidden nodes given input MNIST data as features and use a SciPy-based logistic regression for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features...\n",
      "Classifying...\n",
      "Classification Accuracy: 3612/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kangyetian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "print('Extracting features...')\n",
    "\n",
    "train_features = np.zeros((len(train_dataset), HIDDEN_UNITS))\n",
    "train_labels = np.zeros(len(train_dataset))\n",
    "test_features = np.zeros((len(validation_dataset), HIDDEN_UNITS))\n",
    "test_labels = np.zeros(len(validation_dataset))\n",
    "\n",
    "for i, (batch, labels) in enumerate(train_loader):\n",
    "    batch = batch.view(len(batch), VISIBLE_UNITS)  # flatten input data\n",
    "    try:\n",
    "        train_features[i*BATCH_SIZE:i*BATCH_SIZE+len(batch)] = rbm.compute_hidden(batch).numpy()\n",
    "        train_labels[i*BATCH_SIZE:i*BATCH_SIZE+len(batch)] = labels.numpy()\n",
    "    except:\n",
    "        size = len(train_dataset) - i*BATCH_SIZE\n",
    "        train_features[i*BATCH_SIZE:len(train_dataset)] = rbm.compute_hidden(batch).numpy()[0:size]\n",
    "        train_labels[i*BATCH_SIZE:len(train_dataset)] = labels.numpy()[0:size]        \n",
    "\n",
    "for i, (batch, labels) in enumerate(validation_loader):\n",
    "    batch = batch.view(len(batch), VISIBLE_UNITS)  # flatten input data\n",
    "    try:\n",
    "        test_features[i*BATCH_SIZE:i*BATCH_SIZE+len(batch)] = rbm.compute_hidden(batch).numpy()\n",
    "        test_labels[i*BATCH_SIZE:i*BATCH_SIZE+len(batch)] = labels.numpy()\n",
    "    except:\n",
    "        size = len(test_dataset) - i*BATCH_SIZE\n",
    "        test_features[i*BATCH_SIZE:len(test_dataset)] = rbm.compute_hidden(batch).numpy()[0:size]\n",
    "        test_labels[i*BATCH_SIZE:len(test_dataset)] = labels.numpy()[0:size]  \n",
    "\n",
    "\n",
    "########## CLASSIFICATION ##########\n",
    "print('Classifying...')\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(train_features, train_labels)\n",
    "predictions = clf.predict(test_features)\n",
    "\n",
    "print('Classification Accuracy: %d/%d' % (sum(predictions == test_labels), test_labels.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-330-1692ac3ff58b>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = m(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.303712\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.304038\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 2.298996\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 2.295989\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 2.294553\n",
      "\n",
      "Validation set: Average loss: 2.2968, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 2.305507\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 2.280331\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 2.307274\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 2.277110\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 2.286410\n",
      "\n",
      "Validation set: Average loss: 2.2849, Accuracy: 1348/10000 (13.48%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 2.298855\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 2.262119\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 2.268011\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 2.249558\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 2.275086\n",
      "\n",
      "Validation set: Average loss: 2.2423, Accuracy: 2105/10000 (21.05%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 2.234939\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 2.198911\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 2.179934\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 2.215676\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 2.230592\n",
      "\n",
      "Validation set: Average loss: 2.1886, Accuracy: 2933/10000 (29.33%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 2.152965\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 2.243555\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 2.182941\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 2.196840\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 2.143571\n",
      "\n",
      "Validation set: Average loss: 2.1504, Accuracy: 3028/10000 (30.28%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class Net1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net1, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(28*28, 128)\n",
    "        ## initialize the paramaters with the weights and hidden_bias in trained RBM.\n",
    "        self.fc1.weight = nn.Parameter(torch.transpose(rbm.weights,1,0))\n",
    "        self.fc1.bias = nn.Parameter(rbm.hidden_bias)\n",
    "        \n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        \n",
    "        ## forward x to the first fully connected layer.\n",
    "        x = self.fc1(x)\n",
    "\n",
    "        ## forward x to sigmoid activation function.\n",
    "        x = torch.sigmoid(x)\n",
    "        \n",
    "        ## forward x to the second fully connected layer.\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        ## forward x to softmax activation function.\n",
    "        m = nn.Softmax()\n",
    "        x = m(x)\n",
    "        \n",
    "        return x     \n",
    "    \n",
    "def train(epoch, log_interval=200):\n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        ## zero gradient buffers\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        ## pass data through the network\n",
    "        output = model(data)\n",
    "\n",
    "        ## calculate loss\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        \n",
    "\n",
    "        ## backpropagate\n",
    "        loss.backward()\n",
    "        \n",
    "        ## update weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data.item()))\n",
    "\n",
    "def validate(loss_vector, accuracy_vector):\n",
    "    model.eval()\n",
    "    val_loss, correct = 0, 0\n",
    "    for data, target in validation_loader:\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        output = model(data)\n",
    "        val_loss += criterion(output, target).data.item()\n",
    "        \n",
    "        pred = output.data.max(1)[1]\n",
    "        \n",
    "        correct += pred.eq(target.data).sum()\n",
    "\n",
    "    val_loss /= len(validation_loader)\n",
    "    loss_vector.append(val_loss)\n",
    "\n",
    "    accuracy = 100. * correct.to(torch.float32) / len(validation_loader.dataset)\n",
    "    accuracy_vector.append(accuracy)\n",
    "    \n",
    "    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        val_loss, correct, len(validation_loader.dataset), accuracy))\n",
    "    \n",
    "## Trainig and evaluating 1) MLP\n",
    "model = Net1().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "\n",
    "## define the crosstntropy loss.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 5\n",
    "lossv, accv = [], []\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)\n",
    "    validate(lossv, accv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
