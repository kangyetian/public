{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qusetion 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a). Please fill in the missing code to train 3 different MLPs. And then compare their accuracy values by plotting a bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-fd8ed88fe452>:58: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = m(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.305652\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.303563\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 2.301593\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 2.297927\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 2.299619\n",
      "\n",
      "Validation set: Average loss: 2.2962, Accuracy: 1160/10000 (11.60%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 2.298115\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 2.294742\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 2.290626\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 2.281203\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 2.288285\n",
      "\n",
      "Validation set: Average loss: 2.2786, Accuracy: 2056/10000 (20.56%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 2.284763\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 2.287089\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 2.218360\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 2.245043\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 2.261133\n",
      "\n",
      "Validation set: Average loss: 2.2259, Accuracy: 2106/10000 (21.06%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 2.244194\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 2.242205\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 2.174601\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 2.213241\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 2.054337\n",
      "\n",
      "Validation set: Average loss: 2.1797, Accuracy: 2793/10000 (27.93%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 2.185233\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 2.196271\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 2.170476\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 2.120204\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 2.154789\n",
      "\n",
      "Validation set: Average loss: 2.1397, Accuracy: 3407/10000 (34.07%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.302599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-fd8ed88fe452>:83: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.296185\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 2.280367\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 2.237357\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 2.171144\n",
      "\n",
      "Validation set: Average loss: 2.1451, Accuracy: 5261/10000 (52.61%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 2.116630\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 2.066178\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 1.945291\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 1.962764\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 1.960718\n",
      "\n",
      "Validation set: Average loss: 1.8889, Accuracy: 5947/10000 (59.47%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 1.878425\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 1.818468\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 1.807694\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 1.773010\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 1.767041\n",
      "\n",
      "Validation set: Average loss: 1.7241, Accuracy: 8147/10000 (81.47%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 1.759440\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 1.690286\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 1.636291\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 1.675750\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 1.667331\n",
      "\n",
      "Validation set: Average loss: 1.6780, Accuracy: 8285/10000 (82.85%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 1.735032\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 1.627172\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 1.765334\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 1.721574\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 1.591413\n",
      "\n",
      "Validation set: Average loss: 1.6585, Accuracy: 8347/10000 (83.47%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.305509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-fd8ed88fe452>:107: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.295769\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 2.287098\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 2.266808\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 2.251648\n",
      "\n",
      "Validation set: Average loss: 2.2121, Accuracy: 3932/10000 (39.32%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 2.216092\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 2.160584\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 2.113031\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 1.995226\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 1.959293\n",
      "\n",
      "Validation set: Average loss: 1.8846, Accuracy: 6794/10000 (67.94%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 1.909107\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 1.843522\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 1.900006\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 1.836147\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 1.752794\n",
      "\n",
      "Validation set: Average loss: 1.7779, Accuracy: 7297/10000 (72.97%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 1.721712\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 1.834590\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 1.734699\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 1.851907\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 1.723334\n",
      "\n",
      "Validation set: Average loss: 1.7475, Accuracy: 7423/10000 (74.23%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 1.813181\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 1.769786\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 1.753559\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 1.693215\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 1.736833\n",
      "\n",
      "Validation set: Average loss: 1.7333, Accuracy: 7476/10000 (74.76%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device('cpu')\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_transform = transforms.Compose([ transforms.ToTensor()])\n",
    "\n",
    "test_transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_dataset = datasets.MNIST('./data', \n",
    "                               train=True, \n",
    "                               download=True, \n",
    "                               transform=train_transform)\n",
    "\n",
    "validation_dataset = datasets.MNIST('./data', \n",
    "                                    train=False, \n",
    "                                    transform=test_transform)\n",
    "\n",
    "## construct the loader for training\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "\n",
    "## construct the loader for validation\n",
    "validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=batch_size,\n",
    "                                         shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "class Net1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net1, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(28*28, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        \n",
    "        ## forward x to the first fully connected layer.\n",
    "        x = self.fc1(x)\n",
    "        \n",
    "        ## forward x to sigmoid activation function.\n",
    "        x = torch.sigmoid(x)\n",
    "        \n",
    "        ## forward x to the second fully connected layer.\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        ## forward x to softmax activation function.\n",
    "        m = nn.Softmax()\n",
    "        x = m(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    \n",
    "class Net2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net2, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(28*28, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        \n",
    "        ## forward x to the first fully connected layer.\n",
    "        x = self.fc1(x)\n",
    "        \n",
    "        ## forward x to relu activation function.\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        ## forward x to the second fully connected layer.\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        ## forward x to softmax activation function.\n",
    "        x = F.softmax(x)\n",
    "        \n",
    "        return x    \n",
    "\n",
    "class Net3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net3, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(28*28, 16)\n",
    "        self.fc2 = nn.Linear(16, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        \n",
    "        ## forward x to the first fully connected layer.\n",
    "        x = self.fc1(x)\n",
    "        \n",
    "        ## forward x to relu activation function.\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        ## forward x to the second fully connected layer.\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        ## forward x to softmax activation function.\n",
    "        x = F.softmax(x)\n",
    "        \n",
    "        return x   \n",
    "    \n",
    "def train(epoch, log_interval=200):\n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        ## zero gradient buffers\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        ## pass data through the network\n",
    "        output = model(data)\n",
    "\n",
    "        ## calculate loss\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        ## backpropagate\n",
    "        loss.backward()\n",
    "        \n",
    "        ## update weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data.item()))\n",
    "\n",
    "def validate(loss_vector, accuracy_vector):\n",
    "    model.eval()\n",
    "    val_loss, correct = 0, 0\n",
    "    for data, target in validation_loader:\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        output = model(data)\n",
    "        val_loss += criterion(output, target).data.item()\n",
    "        \n",
    "        pred = output.data.max(1)[1]\n",
    "        \n",
    "        correct += pred.eq(target.data).sum()\n",
    "\n",
    "    val_loss /= len(validation_loader)\n",
    "    loss_vector.append(val_loss)\n",
    "\n",
    "    accuracy = 100. * correct.to(torch.float32) / len(validation_loader.dataset)\n",
    "    accuracy_vector.append(accuracy)\n",
    "    \n",
    "    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        val_loss, correct, len(validation_loader.dataset), accuracy))\n",
    "\n",
    "## Trainig and evaluating 1) MLP\n",
    "model = Net1().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "\n",
    "## define the crosstntropy loss.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 5\n",
    "lossv, accv = [], []\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)\n",
    "    validate(lossv, accv)\n",
    "\n",
    "    \n",
    "## Trainig and evaluating 2) MLP\n",
    "model = Net2().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "\n",
    "## define the crosstntropy loss.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 5\n",
    "lossv, accv = [], []\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)\n",
    "    validate(lossv, accv)\n",
    "\n",
    "## Trainig and evaluating 3) MLP\n",
    "model = Net3().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "\n",
    "## define the crosstntropy loss.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 5\n",
    "lossv, accv = [], []\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)\n",
    "    validate(lossv, accv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b). Please change the batch size and learning rate to train (2) MLP (Net2）as above. And then compare their accuracy values by plotting a matrix with values and colormap. Please note that each time you change the setting and train the MLP, you need to initialize the model again (e.g. \"model = Net2().to(device)\"). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-fd8ed88fe452>:83: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.303677\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.299209\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 2.295861\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 2.289841\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 2.288334\n",
      "\n",
      "Validation set: Average loss: 2.2765, Accuracy: 4516/10000 (45.16%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 2.283466\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 2.251393\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 2.234331\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 2.218730\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 2.177816\n",
      "\n",
      "Validation set: Average loss: 2.1581, Accuracy: 5129/10000 (51.29%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 2.102756\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 2.046618\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 2.028661\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 2.051457\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 1.896242\n",
      "\n",
      "Validation set: Average loss: 1.9601, Accuracy: 5838/10000 (58.38%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 1.981817\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 1.938933\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 1.918158\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 1.825080\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 1.834333\n",
      "\n",
      "Validation set: Average loss: 1.8497, Accuracy: 7049/10000 (70.49%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 1.873732\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 1.885815\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 1.807285\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 1.797657\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 1.808626\n",
      "\n",
      "Validation set: Average loss: 1.7805, Accuracy: 7615/10000 (76.15%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.300081\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.297964\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 2.294010\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 2.282893\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 2.281972\n",
      "\n",
      "Validation set: Average loss: 2.2568, Accuracy: 2891/10000 (28.91%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 2.257916\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 2.269220\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 2.202566\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 2.228472\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 2.164273\n",
      "\n",
      "Validation set: Average loss: 2.1161, Accuracy: 4433/10000 (44.33%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 2.145515\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 2.049307\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 2.074982\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 1.948974\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 1.942770\n",
      "\n",
      "Validation set: Average loss: 1.9425, Accuracy: 6366/10000 (63.66%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 1.888105\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 1.993645\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 1.905892\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 1.864942\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 1.854063\n",
      "\n",
      "Validation set: Average loss: 1.8126, Accuracy: 7770/10000 (77.70%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 1.767723\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 1.786794\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 1.782611\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 1.778143\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 1.766072\n",
      "\n",
      "Validation set: Average loss: 1.7376, Accuracy: 8064/10000 (80.64%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.302879\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.294255\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 2.273992\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 2.250596\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 2.195381\n",
      "\n",
      "Validation set: Average loss: 2.1495, Accuracy: 4749/10000 (47.49%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 2.131444\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 2.082939\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 1.952992\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 1.912304\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 1.877527\n",
      "\n",
      "Validation set: Average loss: 1.8216, Accuracy: 7238/10000 (72.38%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 1.870157\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 1.798276\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 1.798626\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 1.794155\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 1.668349\n",
      "\n",
      "Validation set: Average loss: 1.7081, Accuracy: 8167/10000 (81.67%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 1.726006\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 1.724229\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 1.641520\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 1.706179\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 1.681525\n",
      "\n",
      "Validation set: Average loss: 1.6719, Accuracy: 8290/10000 (82.90%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 1.726305\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 1.645631\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 1.650324\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 1.588436\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 1.616405\n",
      "\n",
      "Validation set: Average loss: 1.6558, Accuracy: 8350/10000 (83.50%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.303589\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.293661\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 2.286408\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 2.234187\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 2.189819\n",
      "\n",
      "Validation set: Average loss: 2.1719, Accuracy: 5766/10000 (57.66%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 2.181672\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 2.093823\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 1.998525\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 1.964267\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 1.933439\n",
      "\n",
      "Validation set: Average loss: 1.8337, Accuracy: 7044/10000 (70.44%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 1.818099\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 1.805310\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 1.764630\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 1.786528\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 1.793996\n",
      "\n",
      "Validation set: Average loss: 1.7096, Accuracy: 8182/10000 (81.82%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 1.685444\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 1.666856\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 1.656670\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 1.755691\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 1.670857\n",
      "\n",
      "Validation set: Average loss: 1.6717, Accuracy: 8306/10000 (83.06%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 1.553532\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 1.698020\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 1.700804\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 1.636885\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 1.640011\n",
      "\n",
      "Validation set: Average loss: 1.6553, Accuracy: 8356/10000 (83.56%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.301838\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.284499\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 2.198849\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 2.058293\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 1.843747\n",
      "\n",
      "Validation set: Average loss: 1.8276, Accuracy: 7392/10000 (73.92%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 1.830161\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 1.810830\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 1.747283\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 1.688767\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 1.743231\n",
      "\n",
      "Validation set: Average loss: 1.6698, Accuracy: 8302/10000 (83.02%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 1.708091\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 1.682758\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 1.703911\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 1.628665\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 1.591623\n",
      "\n",
      "Validation set: Average loss: 1.6459, Accuracy: 8389/10000 (83.89%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 1.647841\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 1.593357\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 1.618910\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 1.629284\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 1.640419\n",
      "\n",
      "Validation set: Average loss: 1.6348, Accuracy: 8426/10000 (84.26%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 1.621223\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 1.582781\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 1.602585\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 1.652805\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 1.634927\n",
      "\n",
      "Validation set: Average loss: 1.6296, Accuracy: 8461/10000 (84.61%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.301436\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.280457\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 2.233119\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 2.035040\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 1.936156\n",
      "\n",
      "Validation set: Average loss: 1.8641, Accuracy: 6538/10000 (65.38%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 1.853106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 1.851582\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 1.720671\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 1.735871\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 1.761347\n",
      "\n",
      "Validation set: Average loss: 1.6818, Accuracy: 8436/10000 (84.36%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 1.676885\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 1.672788\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 1.592944\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 1.621183\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 1.620147\n",
      "\n",
      "Validation set: Average loss: 1.6038, Accuracy: 8946/10000 (89.46%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 1.583347\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 1.596351\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 1.590601\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 1.545100\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 1.586313\n",
      "\n",
      "Validation set: Average loss: 1.5818, Accuracy: 9026/10000 (90.26%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 1.584575\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 1.576379\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 1.565010\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 1.531270\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 1.553793\n",
      "\n",
      "Validation set: Average loss: 1.5703, Accuracy: 9098/10000 (90.98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Trainig and evaluating 2) MLP with the first setting\n",
    "batch_size = 64\n",
    "model = Net2().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.005, momentum=0.5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "epochs = 5\n",
    "lossv, accv = [], []\n",
    "accuracy_matrix = np.array([[0.,0.,0.],[0.,0.,0.]])\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)\n",
    "    validate(lossv, accv)\n",
    "accuracy_matrix[0, 0] = accv[-1]\n",
    "\n",
    "## Trainig and evaluating 2) MLP with the second setting\n",
    "batch_size = 128\n",
    "model = Net2().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.005, momentum=0.5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "epochs = 5\n",
    "lossv, accv = [], []\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)\n",
    "    validate(lossv, accv)\n",
    "accuracy_matrix[1, 0] = accv[-1]\n",
    "    \n",
    "## Trainig and evaluating 2) MLP with the third setting\n",
    "batch_size = 64\n",
    "model = Net2().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "epochs = 5\n",
    "lossv, accv = [], []\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)\n",
    "    validate(lossv, accv)\n",
    "accuracy_matrix[0, 1] = accv[-1]\n",
    "\n",
    "## Trainig and evaluating 2) MLP with the fourth setting\n",
    "batch_size = 128\n",
    "model = Net2().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "epochs = 5\n",
    "lossv, accv = [], []\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)\n",
    "    validate(lossv, accv)\n",
    "accuracy_matrix[1, 1] = accv[-1]\n",
    "\n",
    "\n",
    "## Trainig and evaluating 2) MLP with the fifth setting\n",
    "batch_size = 64\n",
    "model = Net2().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.02, momentum=0.5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "epochs = 5\n",
    "lossv, accv = [], []\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)\n",
    "    validate(lossv, accv)\n",
    "accuracy_matrix[0, 2] = accv[-1]\n",
    "\n",
    "\n",
    "## Trainig and evaluating 2) MLP with the sixth setting\n",
    "batch_size = 128\n",
    "model = Net2().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.02, momentum=0.5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "epochs = 5\n",
    "lossv, accv = [], []\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)\n",
    "    validate(lossv, accv)\n",
    "accuracy_matrix[1, 2] = accv[-1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_set = [64,128]\n",
    "learning_rate_set = [0.005, 0.01, 0.02]\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(accuracy_matrix, cmap=plt.cm.Blues)\n",
    "for i in range(2):\n",
    "    for j in range(3):\n",
    "        c = round( accuracy_matrix[i,j], 2)\n",
    "        ax.text(j,i , str(c), va='center', ha='center')\n",
    "        \n",
    "ax.set_xticks(np.arange(len(learning_rate_set)))\n",
    "ax.set_yticks(np.arange(len(batch_set)))\n",
    "ax.set_xticklabels(learning_rate_set)\n",
    "ax.set_yticklabels(batch_set)\n",
    "ax.set_xlabel(\"learning rate\")\n",
    "ax.set_ylabel(\"batch size\")\n",
    "ax.set_title(\"Accuracy values\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please use “dropout”, “batch normalization” and any “data augmentation” to train to improve the accuracy of (2) MLP (Net2）in Question 1 a. (Batch size is 64 and learning rate is 0.01). Please describe clearly your design choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training images -  60000\n",
      "Size of images -  torch.Size([28, 28])\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device('cpu')\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize(0.5,0.5)])\n",
    "\n",
    "test_transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize(0.5,0.5)])\n",
    "\n",
    "\n",
    "print(\"Number of training images - \", len(train_dataset.data))\n",
    "print(\"Size of images - \", train_dataset.data[0].shape)\n",
    "\n",
    "\n",
    "train_dataset = datasets.MNIST('./data', \n",
    "                               train=True, \n",
    "                               download=True, \n",
    "                               transform=train_transform)\n",
    "\n",
    "\n",
    "# print( train_dataset.__getitem__(1) )\n",
    "validation_dataset = datasets.MNIST('./data', \n",
    "                                    train=False, \n",
    "                                    transform=test_transform)\n",
    "\n",
    "## construct the loader for training\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "\n",
    "## construct the loader for validation\n",
    "validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=batch_size,\n",
    "                                         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net2(\n",
      "  (fc1): Linear(in_features=28224, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net2, self).__init__()\n",
    "               \n",
    "        self.fc1 = nn.Linear(28*28*36, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # upsampling\n",
    "        m = nn.UpsamplingNearest2d(scale_factor= 6)\n",
    "        x = m(x)\n",
    "\n",
    "        \n",
    "        # dropout\n",
    "        m = nn.Dropout(p=0.2)\n",
    "        x = m(x)\n",
    "       \n",
    "        #batch norm\n",
    "        m2 = nn.BatchNorm2d(1, affine=False)\n",
    "        x = m2(x)\n",
    "\n",
    "    \n",
    "        x = x.view(-1, x[0].shape[0]*x[0].shape[1]*x[0].shape[2] )\n",
    "        \n",
    "        ## forward x to the first fully connected layer.\n",
    "        x = self.fc1(x)\n",
    "\n",
    "        ## forward x to relu activation function.\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        ## forward x to the second fully connected layer.\n",
    "        x = self.fc2(x)\n",
    "     \n",
    "        ## forward x to softmax activation function.\n",
    "        x = F.softmax(x, dim=1)\n",
    "        \n",
    "        return x    \n",
    "\n",
    "net = Net2()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.300300\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 1.631561\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 1.510085\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 1.518286\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 1.551883\n",
      "\n",
      "Validation set: Average loss: 1.5396, Accuracy: 9310/10000 (93.10%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 1.559409\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 1.578854\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 1.494314\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 1.533016\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 1.510138\n",
      "\n",
      "Validation set: Average loss: 1.5240, Accuracy: 9448/10000 (94.48%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 1.557608\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 1.508016\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 1.512629\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 1.510983\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 1.500684\n",
      "\n",
      "Validation set: Average loss: 1.5156, Accuracy: 9512/10000 (95.12%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 1.481236\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 1.521193\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 1.506956\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 1.517087\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 1.509387\n",
      "\n",
      "Validation set: Average loss: 1.5105, Accuracy: 9558/10000 (95.58%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 1.493072\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 1.477704\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 1.488656\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 1.515579\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 1.487660\n",
      "\n",
      "Validation set: Average loss: 1.5058, Accuracy: 9590/10000 (95.90%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 1.493752\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 1.527267\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 1.497745\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 1.507769\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 1.510934\n",
      "\n",
      "Validation set: Average loss: 1.5021, Accuracy: 9626/10000 (96.26%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 1.538851\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 1.498168\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 1.473968\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 1.498159\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 1.513209\n",
      "\n",
      "Validation set: Average loss: 1.4998, Accuracy: 9648/10000 (96.48%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 1.474036\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 1.479481\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 1.516102\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 1.512803\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 1.472662\n",
      "\n",
      "Validation set: Average loss: 1.4982, Accuracy: 9662/10000 (96.62%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 1.486403\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 1.487453\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 1.485976\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 1.498509\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 1.502341\n",
      "\n",
      "Validation set: Average loss: 1.4959, Accuracy: 9684/10000 (96.84%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 1.462750\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 1.483953\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 1.474542\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 1.466063\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 1.462616\n",
      "\n",
      "Validation set: Average loss: 1.4935, Accuracy: 9707/10000 (97.07%)\n",
      "\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 1.485593\n",
      "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 1.489880\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 1.477194\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 1.486716\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 1.509429\n",
      "\n",
      "Validation set: Average loss: 1.4936, Accuracy: 9710/10000 (97.10%)\n",
      "\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 1.480057\n",
      "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 1.488806\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 1.527914\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 1.478115\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 1.461675\n",
      "\n",
      "Validation set: Average loss: 1.4925, Accuracy: 9709/10000 (97.09%)\n",
      "\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 1.480115\n",
      "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 1.510176\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 1.499879\n",
      "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 1.464134\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 1.470098\n",
      "\n",
      "Validation set: Average loss: 1.4920, Accuracy: 9717/10000 (97.17%)\n",
      "\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 1.461860\n",
      "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 1.480318\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 1.466020\n",
      "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 1.489731\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 1.485700\n",
      "\n",
      "Validation set: Average loss: 1.4909, Accuracy: 9730/10000 (97.30%)\n",
      "\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 1.471176\n",
      "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 1.492553\n",
      "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 1.463579\n",
      "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 1.493526\n",
      "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 1.466319\n",
      "\n",
      "Validation set: Average loss: 1.4904, Accuracy: 9734/10000 (97.34%)\n",
      "\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 1.501025\n",
      "Train Epoch: 16 [12800/60000 (21%)]\tLoss: 1.506913\n",
      "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 1.481048\n",
      "Train Epoch: 16 [38400/60000 (64%)]\tLoss: 1.475276\n",
      "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 1.497358\n",
      "\n",
      "Validation set: Average loss: 1.4899, Accuracy: 9732/10000 (97.32%)\n",
      "\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 1.469462\n",
      "Train Epoch: 17 [12800/60000 (21%)]\tLoss: 1.489152\n",
      "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 1.480683\n",
      "Train Epoch: 17 [38400/60000 (64%)]\tLoss: 1.513407\n",
      "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 1.487809\n",
      "\n",
      "Validation set: Average loss: 1.4894, Accuracy: 9738/10000 (97.38%)\n",
      "\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 1.509519\n",
      "Train Epoch: 18 [12800/60000 (21%)]\tLoss: 1.476175\n",
      "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 1.466061\n",
      "Train Epoch: 18 [38400/60000 (64%)]\tLoss: 1.477221\n",
      "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 1.514318\n",
      "\n",
      "Validation set: Average loss: 1.4894, Accuracy: 9734/10000 (97.34%)\n",
      "\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 1.496175\n",
      "Train Epoch: 19 [12800/60000 (21%)]\tLoss: 1.462783\n",
      "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 1.479943\n",
      "Train Epoch: 19 [38400/60000 (64%)]\tLoss: 1.464146\n",
      "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 1.483096\n",
      "\n",
      "Validation set: Average loss: 1.4888, Accuracy: 9738/10000 (97.38%)\n",
      "\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 1.466211\n",
      "Train Epoch: 20 [12800/60000 (21%)]\tLoss: 1.461935\n",
      "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 1.466724\n",
      "Train Epoch: 20 [38400/60000 (64%)]\tLoss: 1.500609\n",
      "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 1.470314\n",
      "\n",
      "Validation set: Average loss: 1.4882, Accuracy: 9752/10000 (97.52%)\n",
      "\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "def train(epoch, log_interval=200):\n",
    "    model.train()\n",
    "    \n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        ## zero gradient buffers\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        ## pass data through the network\n",
    "        output = model(data)\n",
    "        \n",
    "        \n",
    "        pred = output.data.max(1)[1]\n",
    "\n",
    "        ## calculate loss\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        ## backpropagate\n",
    "        loss.backward()\n",
    "        \n",
    "        ## update weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data.item()))\n",
    "        \n",
    "        \n",
    "        \n",
    "def validate(loss_vector, accuracy_vector):\n",
    "    model.eval()\n",
    "    val_loss, correct = 0, 0\n",
    "    \n",
    "    pred_all = []\n",
    "    for data, target in validation_loader:\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        output = model(data)\n",
    "        val_loss += criterion(output, target).data.item()\n",
    "        \n",
    "        pred = output.data.max(1)[1]\n",
    "        \n",
    "        pred_all.extend(pred)\n",
    "        \n",
    "        correct += pred.eq(target.data).sum()\n",
    "\n",
    "    val_loss /= len(validation_loader)\n",
    "    loss_vector.append(val_loss)\n",
    "\n",
    "    accuracy = 100. * correct.to(torch.float32) / len(validation_loader.dataset)\n",
    "    accuracy_vector.append(accuracy)\n",
    "    \n",
    "    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        val_loss, correct, len(validation_loader.dataset), accuracy))\n",
    "    \n",
    "    \n",
    "    pred_all = np.array(pred_all)\n",
    "\n",
    "    return pred_all\n",
    "\n",
    "    \n",
    "## Trainig and evaluating 2) MLP\n",
    "model = Net2().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "\n",
    "## define the crosstntropy loss.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 20\n",
    "lossv, accv = [], []\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)\n",
    "    pred_all = validate(lossv,accv)\n",
    "\n",
    "np.save('results.npy',pred_all)\n",
    "\n",
    "\n",
    "print(np.shape(pred_all))\n",
    "#     validate(lossv, accv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please complete the missing code to use RBM to initialize the parameters of the (1) MLP (Net1) in Question 1 a. Compare the accuracy values with and without RBM pretraining by plotting a bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RBM...\n",
      "Epoch Error (epoch=0): 0.0438\n",
      "Epoch Error (epoch=1): 0.0295\n",
      "Epoch Error (epoch=2): 0.0261\n",
      "Epoch Error (epoch=3): 0.0243\n",
      "Epoch Error (epoch=4): 0.0230\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device('cpu')\n",
    "batch_size = 64\n",
    "train_transform = transforms.Compose([ transforms.ToTensor()])\n",
    "\n",
    "test_transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_dataset = datasets.MNIST('./data', \n",
    "                               train=True,                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            download=True, \n",
    "                               transform=train_transform)\n",
    "\n",
    "validation_dataset = datasets.MNIST('./data', \n",
    "                                    train=False, \n",
    "                                    transform=test_transform)\n",
    "\n",
    "## construct the loader for training\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "\n",
    "## construct the loader for validation\n",
    "validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=batch_size,\n",
    "                                         shuffle=False)\n",
    "\n",
    "class RBM():\n",
    "\n",
    "    def __init__(self, num_visible, num_hidden, k, learning_rate=0.1):\n",
    "        self.num_visible = num_visible\n",
    "        self.num_hidden = num_hidden\n",
    "        self.k = k\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        self.weights = torch.randn(num_visible, num_hidden) * 0.01\n",
    "        self.visible_bias = torch.ones(num_visible) * 0.01\n",
    "        self.hidden_bias = torch.zeros(num_hidden)\n",
    "        \n",
    "    def _sigmoid(self, x):\n",
    "        return 1 / (1 + torch.exp(-x))\n",
    "\n",
    "    def _random_probabilities(self, num):\n",
    "        random_probabilities = torch.rand(num)\n",
    "        return random_probabilities\n",
    "    \n",
    "## compute the probability of hidden nodes given visible nodes.\n",
    "    def compute_hidden(self, visible_probabilities):\n",
    "        \n",
    "        hidden_activations = torch.matmul(visible_probabilities, self.weights) + self.hidden_bias\n",
    "        \n",
    "        hidden_probabilities = self._sigmoid(hidden_activations)\n",
    "        return hidden_probabilities\n",
    "\n",
    "## compute the probability of visible nodes given hidden nodes.\n",
    "    def compute_visible(self, hidden_probabilities):\n",
    "        \n",
    "        visible_activations = torch.matmul(hidden_probabilities, self.weights.t()) + self.visible_bias\n",
    "        \n",
    "        visible_probabilities = self._sigmoid(visible_activations)\n",
    "        return visible_probabilities\n",
    "    \n",
    "## Contrastive Divergence (CD-k)\n",
    "    def contrastive_divergence(self, input_data):\n",
    "        \n",
    "        positive_hidden_probabilities = self.compute_hidden(input_data)\n",
    "        \n",
    "        ## sample a hidden activation vector from its probability distribution\n",
    "        positive_hidden_activations = (positive_hidden_probabilities >= self._random_probabilities(self.num_hidden)).float()\n",
    "        \n",
    "        \n",
    "        ## compute the positive gradient\n",
    "        positive_associations = torch.matmul(input_data.t(), positive_hidden_activations)\n",
    "\n",
    "\n",
    "        hidden_activations = positive_hidden_activations\n",
    "\n",
    "        for step in range(self.k):\n",
    "            visible_probabilities = self.compute_visible(hidden_activations)\n",
    "            hidden_probabilities = self.compute_hidden(visible_probabilities)\n",
    "            \n",
    "            ## resample a hidden activation vector from its probability distribution\n",
    "            hidden_activations = (hidden_probabilities >= self._random_probabilities(self.num_hidden)).float()\n",
    "\n",
    "\n",
    "        negative_visible_probabilities = visible_probabilities\n",
    "        negative_hidden_probabilities = hidden_probabilities\n",
    "        \n",
    "        ## compute the nagetive gradient\n",
    "        negative_associations = torch.matmul(negative_visible_probabilities.t(), negative_hidden_probabilities)\n",
    "\n",
    "        \n",
    "        batch_size = input_data.size(0)\n",
    "        \n",
    "        ## update weights\n",
    "        self.weights += (positive_associations - negative_associations) * self.learning_rate / batch_size\n",
    "        \n",
    "        ## update bias of visible units\n",
    "        self.visible_bias += torch.sum(input_data - negative_visible_probabilities, dim=0) * self.learning_rate / batch_size\n",
    "\n",
    "        ## update bias of hidden units\n",
    "        self.hidden_bias += torch.sum(positive_hidden_probabilities - negative_hidden_probabilities, dim=0) * self.learning_rate / batch_size\n",
    "\n",
    "        ## compute reconstruction error\n",
    "        error = torch.mean((input_data - negative_visible_probabilities)**2)\n",
    "\n",
    "        return error\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "VISIBLE_UNITS = 784  # 28 x 28 images\n",
    "HIDDEN_UNITS = 128\n",
    "CD_K = 3\n",
    "EPOCHS = 5\n",
    "\n",
    "########## TRAINING RBM ##########\n",
    "print('Training RBM...')\n",
    "\n",
    "rbm = RBM(VISIBLE_UNITS, HIDDEN_UNITS, CD_K)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    epoch_error = 0.0\n",
    "    num_batch = 0\n",
    "    for batch, _ in train_loader:\n",
    "        batch = batch.view(len(batch), VISIBLE_UNITS)  # flatten input data\n",
    "\n",
    "        batch_error = rbm.contrastive_divergence(batch)\n",
    "        epoch_error += batch_error\n",
    "        num_batch = num_batch + 1\n",
    "\n",
    "    print('Epoch Error (epoch=%d): %.4f' % (epoch, epoch_error/num_batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now check whether the trained RBM model can extract features from the images.\n",
    "\n",
    "We calculate the probability of hidden nodes given input MNIST data as features and use a SciPy-based logistic regression for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features...\n",
      "Classifying...\n",
      "Classification Accuracy: 9404/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kangyetian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "print('Extracting features...')\n",
    "\n",
    "train_features = np.zeros((len(train_dataset), HIDDEN_UNITS))\n",
    "train_labels = np.zeros(len(train_dataset))\n",
    "test_features = np.zeros((len(validation_dataset), HIDDEN_UNITS))\n",
    "test_labels = np.zeros(len(validation_dataset))\n",
    "\n",
    "for i, (batch, labels) in enumerate(train_loader):\n",
    "    batch = batch.view(len(batch), VISIBLE_UNITS)  # flatten input data\n",
    "    try:\n",
    "        train_features[i*BATCH_SIZE:i*BATCH_SIZE+len(batch)] = rbm.compute_hidden(batch).numpy()\n",
    "        train_labels[i*BATCH_SIZE:i*BATCH_SIZE+len(batch)] = labels.numpy()\n",
    "    except:\n",
    "        size = len(train_dataset) - i*BATCH_SIZE\n",
    "        train_features[i*BATCH_SIZE:len(train_dataset)] = rbm.compute_hidden(batch).numpy()[0:size]\n",
    "        train_labels[i*BATCH_SIZE:len(train_dataset)] = labels.numpy()[0:size]        \n",
    "\n",
    "for i, (batch, labels) in enumerate(validation_loader):\n",
    "    batch = batch.view(len(batch), VISIBLE_UNITS)  # flatten input data\n",
    "    try:\n",
    "        test_features[i*BATCH_SIZE:i*BATCH_SIZE+len(batch)] = rbm.compute_hidden(batch).numpy()\n",
    "        test_labels[i*BATCH_SIZE:i*BATCH_SIZE+len(batch)] = labels.numpy()\n",
    "    except:\n",
    "        size = len(test_dataset) - i*BATCH_SIZE\n",
    "        test_features[i*BATCH_SIZE:len(test_dataset)] = rbm.compute_hidden(batch).numpy()[0:size]\n",
    "        test_labels[i*BATCH_SIZE:len(test_dataset)] = labels.numpy()[0:size]  \n",
    "\n",
    "\n",
    "########## CLASSIFICATION ##########\n",
    "print('Classifying...')\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(train_features, train_labels)\n",
    "predictions = clf.predict(test_features)\n",
    "\n",
    "print('Classification Accuracy: %d/%d' % (sum(predictions == test_labels), test_labels.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-8525b86da34f>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = m(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.310543\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.259072\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 2.155857\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 2.101352\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 2.081429\n",
      "\n",
      "Validation set: Average loss: 2.0719, Accuracy: 4487/10000 (44.87%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 2.071383\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 2.107463\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 1.975177\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 1.963709\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 1.916860\n",
      "\n",
      "Validation set: Average loss: 1.8803, Accuracy: 7819/10000 (78.19%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 1.876910\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 1.777146\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 1.745756\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 1.827403\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 1.769218\n",
      "\n",
      "Validation set: Average loss: 1.7794, Accuracy: 8079/10000 (80.79%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 1.885615\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 1.798357\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 1.801755\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 1.718287\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 1.728951\n",
      "\n",
      "Validation set: Average loss: 1.7375, Accuracy: 8170/10000 (81.70%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 1.748271\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 1.700515\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 1.744558\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 1.727352\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 1.716665\n",
      "\n",
      "Validation set: Average loss: 1.7143, Accuracy: 8241/10000 (82.41%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class Net1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net1, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(28*28, 128)\n",
    "        ## initialize the paramaters with the weights and hidden_bias in trained RBM.\n",
    "        self.fc1.weight = nn.Parameter(torch.transpose(rbm.weights,1,0))\n",
    "        self.fc1.bias = nn.Parameter(rbm.hidden_bias)\n",
    "        \n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        \n",
    "        ## forward x to the first fully connected layer.\n",
    "        x = self.fc1(x)\n",
    "\n",
    "        ## forward x to sigmoid activation function.\n",
    "        x = torch.sigmoid(x)\n",
    "        \n",
    "        ## forward x to the second fully connected layer.\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        ## forward x to softmax activation function.\n",
    "        m = nn.Softmax()\n",
    "        x = m(x)\n",
    "        \n",
    "        return x     \n",
    "    \n",
    "def train(epoch, log_interval=200):\n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        ## zero gradient buffers\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        ## pass data through the network\n",
    "        output = model(data)\n",
    "\n",
    "        ## calculate loss\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        \n",
    "\n",
    "        ## backpropagate\n",
    "        loss.backward()\n",
    "        \n",
    "        ## update weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data.item()))\n",
    "\n",
    "def validate(loss_vector, accuracy_vector):\n",
    "    model.eval()\n",
    "    val_loss, correct = 0, 0\n",
    "    for data, target in validation_loader:\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        output = model(data)\n",
    "        val_loss += criterion(output, target).data.item()\n",
    "        \n",
    "        pred = output.data.max(1)[1]\n",
    "        \n",
    "        correct += pred.eq(target.data).sum()\n",
    "\n",
    "    val_loss /= len(validation_loader)\n",
    "    loss_vector.append(val_loss)\n",
    "\n",
    "    accuracy = 100. * correct.to(torch.float32) / len(validation_loader.dataset)\n",
    "    accuracy_vector.append(accuracy)\n",
    "    \n",
    "    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        val_loss, correct, len(validation_loader.dataset), accuracy))\n",
    "    \n",
    "## Trainig and evaluating 1) MLP\n",
    "model = Net1().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "\n",
    "## define the crosstntropy loss.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 5\n",
    "lossv, accv_rbm = [], []\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)\n",
    "    validate(lossv, accv_rbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-28-c3d031cd4edc>:60: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = m(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.302446\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.303570\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 2.304434\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 2.292588\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 2.295793\n",
      "\n",
      "Validation set: Average loss: 2.2926, Accuracy: 1135/10000 (11.35%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 2.295002\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 2.281097\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 2.281479\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 2.266376\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 2.261847\n",
      "\n",
      "Validation set: Average loss: 2.2665, Accuracy: 1977/10000 (19.77%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 2.289189\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 2.261223\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 2.287358\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 2.203677\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 2.247274\n",
      "\n",
      "Validation set: Average loss: 2.2089, Accuracy: 2622/10000 (26.22%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 2.217066\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 2.299752\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 2.184547\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 2.176118\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 2.217945\n",
      "\n",
      "Validation set: Average loss: 2.1621, Accuracy: 3007/10000 (30.07%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 2.211450\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 2.155785\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 2.105087\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 2.107630\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 2.060118\n",
      "\n",
      "Validation set: Average loss: 2.1244, Accuracy: 3494/10000 (34.94%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for comparison, run the net1 again in Q1\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device('cpu')\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_transform = transforms.Compose([ transforms.ToTensor()])\n",
    "\n",
    "test_transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_dataset = datasets.MNIST('./data', \n",
    "                               train=True, \n",
    "                               download=True, \n",
    "                               transform=train_transform)\n",
    "\n",
    "validation_dataset = datasets.MNIST('./data', \n",
    "                                    train=False, \n",
    "                                    transform=test_transform)\n",
    "\n",
    "## construct the loader for training\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "\n",
    "## construct the loader for validation\n",
    "validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=batch_size,\n",
    "                                         shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "class Net1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net1, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(28*28, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        \n",
    "        ## forward x to the first fully connected layer.\n",
    "        x = self.fc1(x)\n",
    "        \n",
    "        ## forward x to sigmoid activation function.\n",
    "        x = torch.sigmoid(x)\n",
    "        \n",
    "        ## forward x to the second fully connected layer.\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        ## forward x to softmax activation function.\n",
    "        m = nn.Softmax()\n",
    "        x = m(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "def train(epoch, log_interval=200):\n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        ## zero gradient buffers\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        ## pass data through the network\n",
    "        output = model(data)\n",
    "\n",
    "        ## calculate loss\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        ## backpropagate\n",
    "        loss.backward()\n",
    "        \n",
    "        ## update weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data.item()))\n",
    "\n",
    "def validate(loss_vector, accuracy_vector):\n",
    "    model.eval()\n",
    "    val_loss, correct = 0, 0\n",
    "    for data, target in validation_loader:\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        output = model(data)\n",
    "        val_loss += criterion(output, target).data.item()\n",
    "        \n",
    "        pred = output.data.max(1)[1]\n",
    "        \n",
    "        correct += pred.eq(target.data).sum()\n",
    "\n",
    "    val_loss /= len(validation_loader)\n",
    "    loss_vector.append(val_loss)\n",
    "\n",
    "    accuracy = 100. * correct.to(torch.float32) / len(validation_loader.dataset)\n",
    "    accuracy_vector.append(accuracy)\n",
    "    \n",
    "    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        val_loss, correct, len(validation_loader.dataset), accuracy))\n",
    "\n",
    "## Trainig and evaluating 1) MLP\n",
    "model = Net1().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "\n",
    "## define the crosstntropy loss.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 5\n",
    "lossv, accv2 = [], []\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)\n",
    "    validate(lossv, accv2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "labels = ['Ep1', 'Ep2', 'Ep3', 'Ep4', 'Ep5']\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.35  # the width of the bars    \n",
    "\n",
    "# #round to integer to make the bar chart more friendly\n",
    "# accv_rbm_round = [0,0,0,0,0] \n",
    "# accv2_round = [0,0,0,0,0]\n",
    "# for i in range(5):\n",
    "#     accv_rbm_round[i] = accv_rbm[i].round() \n",
    "#     accv2_round[i] = accv2[i].round() \n",
    "\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, accv_rbm, width, label='with rbm')\n",
    "rects2 = ax.bar(x + width/2, accv2, width, label='without rbm')\n",
    "\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Accuracy for each epoch')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "def autolabel(rects):\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{}'.format(height),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
